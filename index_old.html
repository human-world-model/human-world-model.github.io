<!DOCTYPE html>
<html>
<head>
  <style>
  video.center {
    display: block;
    margin-left: auto;
    margin-right: auto;
  }
  image.center {
    display: block;
    margin-left: auto;
    margin-right: auto;
  }
  </style>

  <meta charset="utf-8">
  <meta name="description" content="Structured World Models from Human Videos">
  <meta name="keywords" content="Human Videos, World Models, Machine Learning, Affordances, Continual Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:site_name" content="Structured World Models from Human Videos" />
  <meta property="og:type" content="video.other" />
  <meta property="og:title" content="Structured World Models from Human Videos" />
  <meta property="og:description" content="Structured World Models from Human Videos" />
  <meta property="og:url" content="http://human-world-model.github.io" />
  <meta property="og:image" content="http://human-world-model.github.io/resources/teaser.png" />
  <meta property="og:video" content="http://human-world-model.github.io/resources/main_vid.mp4" />

  <meta property="article:publisher" content="http://human-world-model.github.io/" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Structured World Models from Human Videos" />
  <meta name="twitter:url" content="http://human-world-model.github.io/" />
  <meta name="twitter:image" content="http://human-world-model.github.io/resources/teaser.png"/>
  <meta property="og:image:width" content="1600" />
  <meta property="og:image:height" content="900" />

  <script src="https://www.youtube.com/iframe_api"></script>
  <meta name="twitter:card" content="player" />
  <meta name="twitter:player" content="" />
  <meta name="twitter:player:width" content="640" />
  <meta name="twitter:player:height" content="360" />


  <title>Structured World Models from Human Videos</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Structured World Models from Human Videos </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Anonymous RSS Submission
              <br>
              Paper ID: 278
            </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- arXiv Link. -->
              <!-- Video Link. -->
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>



<section class="section" style="padding-bottom: 0">
  <div class="container">
    <div id="method_video" class="columns is-centered has-text-centered">
      <div class="column is-two-thirds no-bottom-padding">
        <video width="960" height="720" loop controls picture-in-picture>
          <source src="./resources/main_vid.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          In this paper, we tackle the problem of learning complex, general behaviors directly in the real world. We propose an approach for robots to efficiently learn manipulation skills using only a handful of real-world interaction trajectories from many different settings. Inspired by the success of learning from large-scale datasets in the fields of computer vision and natural language, our belief is that in order to efficiently learn, a robot must be able to leverage internet-scale, human video data. Humans interact with the world in many interesting ways, which can allow a robot to not only build an understanding of useful actions and affordances but also how these actions affect the world for manipulation. Our approach builds a structured, human-centric action space grounded in visual affordances learned from human videos. Further, we train a world model on human videos and fine-tune on a small amount of robot interaction data without any task supervision. We show that this approach of affordance-space world models enables different robots to learn various manipulation skills in complex settings, in under 30 minutes of interaction.
          </p>
        </div>
      </div>
    </div>
  </div>

  <!--/ Paper video. -->
  <br/>
  <br/>
  
</section>





<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="large-font bottom_buttons" disabled>
        <i class="fab fa-github"></i>
      </a> -->
      <!-- <br /> -->
      <p>Page template borrowed from <a href="https://nerfies.github.io"><span class="dnerf">Nerfies</span></a>.</p>
    </div>
  </div>
</footer>

</body>
</html>
